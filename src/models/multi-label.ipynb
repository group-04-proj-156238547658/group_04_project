{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e370e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/8wk8p3y12wl070d4bvc1nrf40000gn/T/ipykernel_66382/537328359.py:34: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  firstlast = counts[:5].append(counts[-5:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extract method                                ...</td>\n",
       "      <td>4225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rename method                                 ...</td>\n",
       "      <td>2940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>move method                                   ...</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>move attribute                                ...</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rename class                                  ...</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pull up attribute                             ...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extract interface                             ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>extract superclass                            ...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>push down method                              ...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>push down attribute                           ...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index  count\n",
       "0  extract method                                ...   4225\n",
       "1  rename method                                 ...   2940\n",
       "2  move method                                   ...   1441\n",
       "3  move attribute                                ...    957\n",
       "4  rename class                                  ...    801\n",
       "5  pull up attribute                             ...    186\n",
       "6  extract interface                             ...    149\n",
       "7  extract superclass                            ...    132\n",
       "8  push down method                              ...    112\n",
       "9  push down attribute                           ...    102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "df_text = pd.read_csv('./dataset/TextPreprocessed.csv', encoding='iso-8859-1')\n",
    "# print(df_text.head())\n",
    "df_tags = pd.read_csv('./dataset/Tag.csv', encoding='iso-8859-1')\n",
    "\n",
    "num_classes = 14\n",
    "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
    "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
    "df_tags.Tag = df_tags.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
    "df_tags = df_tags.dropna()\n",
    "\n",
    "counts = df_tags.Tag.value_counts()\n",
    "firstlast = counts[:5].append(counts[-5:])\n",
    "firstlast.reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956ff917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_for_question(question_id):\n",
    "    return df_tags[df_tags['Id'] == question_id].Tag.values\n",
    "\n",
    "def add_tags_column(row):\n",
    "    row['Tags'] = tags_for_question(row['Id'])\n",
    "    return row\n",
    "\n",
    "df_questions = df_text.apply(add_tags_column, axis=1)\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions.Tags)\n",
    "Y = multilabel_binarizer.transform(df_questions.Tags)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(df_questions.Text.values.astype('U'))\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "ros = RandomOverSampler(random_state=9000)\n",
    "X_tfidf_resampled, Y_tfidf_resampled = ros.fit_resample(X_tfidf, Y)\n",
    "\n",
    "#X_tfidf_resampled, Y_tfidf_resampled = ros.fit_sample(X_tfidf, Y)\n",
    "\n",
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf_resampled, Y_tfidf_resampled, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9c098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    print(y_true.shape[0])\n",
    "    print(y_pred)\n",
    "\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set(np.where(y_true[i])[0])\n",
    "        set_pred = set(np.where(y_pred[i])[0])\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            # tmp_a = len(set_true.union(set_pred))\n",
    "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    # print(acc_list)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "def print_score(y_pred, clf):\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    cm = multilabel_confusion_matrix(y_test_tfidf, y_pred)\n",
    "    cm_p = (np.round(cm / np.sum(cm, axis=1, keepdims=True) * 100, 2))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    for i in range(len(cm)):\n",
    "        print(f\"Confusion Matrix for Label {i + 1}:\\n\", cm_p[i])\n",
    "        print()\n",
    "    #print(\"Confusion Matrix:{}\".format)\n",
    "    print(\"Hamming loss: {}\".format(hamming_loss(y_test_tfidf, y_pred)))\n",
    "    print(\"Hamming score: {}\".format(hamming_score(y_test_tfidf, y_pred)))\n",
    "    print('Subset accuracy: {0}'.format(accuracy_score(y_test_tfidf, y_pred, normalize=True, sample_weight=None)))\n",
    "    print('Subset precision: {0}'.format(precision_score(y_test_tfidf, y_pred, average='samples')))\n",
    "    print(\"---\")\n",
    "\n",
    "# sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=6, tol=None)\n",
    "#lr = LogisticRegression()\n",
    "#mnb = MultinomialNB()\n",
    "svm = LinearSVC()\n",
    "#rf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50852b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clf:  LinearSVC\n",
      "Confusion Matrix for Label 1:\n",
      " [[99.51  9.22]\n",
      " [ 0.49 90.78]]\n",
      "\n",
      "Confusion Matrix for Label 2:\n",
      " [[93.28 43.48]\n",
      " [ 6.72 56.52]]\n",
      "\n",
      "Confusion Matrix for Label 3:\n",
      " [[99.38 10.11]\n",
      " [ 0.62 89.89]]\n",
      "\n",
      "Confusion Matrix for Label 4:\n",
      " [[97.34 10.13]\n",
      " [ 2.66 89.87]]\n",
      "\n",
      "Confusion Matrix for Label 5:\n",
      " [[99.02 10.66]\n",
      " [ 0.98 89.34]]\n",
      "\n",
      "Confusion Matrix for Label 6:\n",
      " [[97.35 17.24]\n",
      " [ 2.65 82.76]]\n",
      "\n",
      "Confusion Matrix for Label 7:\n",
      " [[97.73 10.39]\n",
      " [ 2.27 89.61]]\n",
      "\n",
      "Confusion Matrix for Label 8:\n",
      " [[96.08 16.17]\n",
      " [ 3.92 83.83]]\n",
      "\n",
      "Confusion Matrix for Label 9:\n",
      " [[99.41  9.56]\n",
      " [ 0.59 90.44]]\n",
      "\n",
      "Confusion Matrix for Label 10:\n",
      " [[98.28  8.16]\n",
      " [ 1.72 91.84]]\n",
      "\n",
      "Confusion Matrix for Label 11:\n",
      " [[98.64  7.19]\n",
      " [ 1.36 92.81]]\n",
      "\n",
      "Confusion Matrix for Label 12:\n",
      " [[98.69  6.08]\n",
      " [ 1.31 93.92]]\n",
      "\n",
      "Confusion Matrix for Label 13:\n",
      " [[97.22 10.13]\n",
      " [ 2.78 89.87]]\n",
      "\n",
      "Confusion Matrix for Label 14:\n",
      " [[94.29 28.57]\n",
      " [ 5.71 71.43]]\n",
      "\n",
      "Hamming loss: 0.02917808219178082\n",
      "7300\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Hamming score: 0.6755479452054794\n",
      "Subset accuracy: 0.6754794520547945\n",
      "Subset precision: 0.6755479452054794\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       535\n",
      "           1       0.57      0.07      0.13       525\n",
      "           2       0.90      0.92      0.91       531\n",
      "           3       0.90      0.66      0.76       539\n",
      "           4       0.89      0.87      0.88       511\n",
      "           5       0.83      0.65      0.73       519\n",
      "           6       0.90      0.71      0.79       544\n",
      "           7       0.84      0.45      0.58       499\n",
      "           8       0.90      0.92      0.91       494\n",
      "           9       0.92      0.77      0.84       512\n",
      "          10       0.93      0.82      0.87       519\n",
      "          11       0.94      0.82      0.88       507\n",
      "          12       0.90      0.65      0.75       547\n",
      "          13       0.71      0.21      0.33       518\n",
      "\n",
      "   micro avg       0.89      0.68      0.77      7300\n",
      "   macro avg       0.86      0.68      0.73      7300\n",
      "weighted avg       0.86      0.68      0.73      7300\n",
      " samples avg       0.68      0.68      0.68      7300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luna/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luna/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for classifier in [svm]:\n",
    "    clf = OneVsRestClassifier(classifier)\n",
    "    clf.fit(x_train_tfidf, y_train_tfidf)\n",
    "    y_pred = clf.predict(x_test_tfidf)\n",
    "    print_score(y_pred, classifier)\n",
    "    print(classification_report(y_test_tfidf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af7740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
